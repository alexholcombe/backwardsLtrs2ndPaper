---
title: "InferentialStats"
author: "Alex Holcombe"
date: "2/27/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read in parameter estimates

```{r}

estimates<- read.csv(file="Results/backwards2E1_paramEstimates.csv", header=TRUE, sep=",")
estimates$X<- NULL #Not sure where X comes from but it's just a row number
```


Exclude Ss who failed likelihood ratio test in all four cases.
Create new column nPassed for in how many conditions they passed (out of 4).

```{r}
library(dplyr)

estimates<- estimates %>% mutate(mixModelFitsBetter = pLRtest<.05)
                       
condtnVariableNames <- c("subject","stream", "orientation")  

e<- estimates %>%  group_by(subject) %>%
  summarise(nPassed = sum(mixModelFitsBetter)) 
estimates<- merge(e,estimates) 

estimates<- estimates %>% mutate( exclude = (nPassed==0)  )
```


Assess the size of the effect to inform Bayesian test of next experiment (probably use raw units)

```{r, echo=FALSE, message=FALSE}
require(ggplot2)
gg<-ggplot(estimates, aes(x=stream, y=efficacy)) + geom_point(color="grey") + stat_summary(fun.y="mean",geom="point",size=4, alpha=.5)
show(gg)

library(data.table)

#The below works but drops many variables, so think about merging later
eff<- data.table::dcast(estimates, orientation+subject+nPassed~stream,value.var="efficacy")
eff$dv<-"efficacy"
lat<-data.table::dcast(estimates, orientation+subject+nPassed~stream,value.var="latency") 
lat$dv<-"latency"
pre<-data.table::dcast(estimates, orientation+subject+nPassed~stream,value.var="precision") 
pre$dv<-"precision"
all<-rbind(eff,lat,pre)
#I tried to do the above with a single command but makes an error even though StackOverflow example works
#https://stackoverflow.com/questions/37332076/from-long-to-wide-data-with-multiple-columns/37332345
# data.table::dcast(estimates, orientation+subject+nPassed~stream,value.var=c("efficacy","latency"))
head(eff)
```


Calculate bias
```{r , fig.height=20, fig.width=5}
all$leftBias<- all$Left - all$Right
hh<-ggplot(all, aes(x=orientation, y=leftBias)) + facet_grid(.~dv) + geom_point(color="grey") + stat_summary(fun.y="mean",geom="point",size=4, alpha=.5)
hh<-hh+stat_summary(fun.data="mean_cl_boot",geom="errorbar",width=.3,conf.int=.95,
                  width=5,size=1) 
show(hh)
```

Print effect size
```{r}
leftBiasCanonical <- mean(   filter(all,dv=="efficacy" & orientation=="Canonical")$leftBias  )
leftBiasInverted<- mean(   filter(all,dv=="efficacy" & orientation=="Inverted")$leftBias  )
leftBiasDiff<- leftBiasCanonical - leftBiasInverted
```

The leftBiasDiff for this experiment is `r leftBiasDiff`, very healthy.


```{r, echo=FALSE}
P1E1canonical=.23
P1E1reversed= .062
P1E2canonical=.218 #sd=.034
P1E2inverted=.017 #sd=.049
P1E2vertCanon=.188 #sd=.043
P1E2vertUpright= -.07 #sd=.049
P1E1leftBiasDiff<- P1E1canonical-P1E1reversed
P1E2leftBiasDiff<- P1E2canonical - P1E2inverted
P1E2vertBiasDiff<- P1E2vertCanon - P1E2vertUpright
```

What was it for the first paper? For E1,`r P1E1canonical`  Canonical and 
`r P1E1reversed` Mirror-reversed. Difference is `r P1E1canonical-P1E1reversed`
. For E2, bias difference very similar at `r P1E2canonical - P1E2inverted`.
For E2 vertical arrangement, `r P1E2vertCanon - P1E2vertUpright`


Do conventional stats.
```{r}

require(ez)

aa <- ezANOVA(data=filter(all,dv=="efficacy"), dv=leftBias, within=orientation, wid=subject)
cat("F=", aa$ANOVA$F, " p=", aa$ANOVA$p, "\n", sep="")

```

Do Bayesian t-test. That is, take the likelihood of the left bias difference observed under the prior and divide it by the likelihood of the left bias difference observed under the null.

http://jeffrouder.blogspot.com.au/2016/01/what-priors-should-i-use-part-i.html
For the null model, the bias is just zero (delta function).

For our model, support is zero to infinity. 
```{r}

#Specify alternative hypothesis (prior)

#Specify Alternative (up to constant of proportionality)
lo=0 #lower bound of support
hi=Inf #upper bound of support
altDens=function(delta) {
  y= dnorm(delta,.3,.1)
  y=y*as.integer(delta>lo)*as.integer(delta<hi) #multiply by zero if outside of support
}

#Normalize alternative density in case user does not, 
K=1/integrate(altDens,lower=lo,upper=hi)$value
f=function(delta) K*altDens(delta)

delta=seq(-1,1.2,.01)

#Plot Alternative as a density and Null as a point arrow
maxAlt=max(f(delta))
plot(delta,f(delta),typ='n',xlab="Left bias difference",ylab="Density",ylim=c(0,1.4*maxAlt),main="Models")
arrows(0,0,0,1.3*maxAlt,col='darkblue',lwd=2)
lines(delta,f(delta),col='green',lwd=2)
legend("topright",legend=c("Null","Alternative","Previous findings"),col=c('darkblue','green','black'),lwd=2)

points(P1E1leftBiasDiff,.1,pch=19)
points(P1E2leftBiasDiff,.1,pch=19)
points(P1E2vertBiasDiff,.1,pch=22)
points(leftBiasDiff,.1,pch=23)

```

Do the correlogram and correlation