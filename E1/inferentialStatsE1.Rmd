---
title: "InferentialStats"
author: "Alex Holcombe"
date: "2/27/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read in parameter estimates

```{r}

resultsPath <- file.path("Results")
estimates<- read.csv(file=file.path(resultsPath,"backwards2E1_paramEstimates.csv"), header=TRUE, sep=",")
estimates$X<- NULL #Not sure where X comes from but it's just a row number
library(tidyverse)
estimates <- as_tibble(estimates)
```

## Exclusions

Exclusion based on low efficacy - "participants whose efficacy in either RSVP stream in any condition  lower than 10% (as indicated by the mixture modeling code)  removed from data analysis to reduce floor effects."

Exclude Ss who failed likelihood ratio test in all four cases.
Create new column nPassed for in how many conditions they passed (out of 4).

There was no mention of the LRtest in the prereg, forgot to mention that probably. But I looked at it and was fairly consistent with low efficacy.

```{r}

#lowEff <- estimates %>% filter(efficacy <= .1)

lowE<- estimates %>%  group_by(subject) %>%
  summarise(exclude = any(efficacy<.1) )

#estimates<- estimates %>% mutate(mixModelFitsBetter = pLRtest<.05)
                       
estimates<- merge(lowE,estimates) 
estimates <- as_tibble(estimates)

toExclude <- unique((estimates %>% filter(exclude==TRUE))$subject)
```

Num to exclude is `r length(toExclude)`
```{r}
write_tsv(estimates,path=file.path(resultsPath,'backwards2E1_paramEstimatesWithExcludeColumn.tsv'))

```


Assess the size of the effect 

```{r, echo=FALSE, message=FALSE}
require(ggplot2)
gg<-ggplot(estimates, aes(x=stream, y=efficacy)) + geom_point(color="grey") + stat_summary(fun.y="mean",geom="point",size=4, alpha=.5)
show(gg)

require(papaja)
require(Hmisc) #for mean_cl_boot
dodg = .3
gg<-ggplot(estimates %>% filter(exclude==FALSE), 
           aes(x=orientation, y=efficacy, color=stream)) + 
          geom_point(position = position_dodge(width = dodg)) + 
  stat_summary(fun.y="mean",geom="point",size=8, alpha=.5, position = position_dodge(width = dodg)) +
  stat_summary(fun.data = mean_cl_boot, geom="errorbar", width=0.4, position = position_dodge(width = dodg)) +
  theme_apa() +ggtitle('good')
show(gg)

```

library(data.table)

#The below works but drops many variables, so think about merging later
eff<- data.table::dcast(estimates, orientation+subject+nPassed~stream,value.var="efficacy")
eff$dv<-"efficacy"
lat<-data.table::dcast(estimates, orientation+subject+nPassed~stream,value.var="latency") 
lat$dv<-"latency"
pre<-data.table::dcast(estimates, orientation+subject+nPassed~stream,value.var="precision") 
pre$dv<-"precision"
all<-rbind(eff,lat,pre)
#I tried to do the above with a single command but makes an error even though StackOverflow example works
#https://stackoverflow.com/questions/37332076/from-long-to-wide-data-with-multiple-columns/37332345
# data.table::dcast(estimates, orientation+subject+nPassed~stream,value.var=c("efficacy","latency"))
head(eff)
```


Calculate bias
```{r , fig.height=20, fig.width=5}
all$leftBias<- all$Left - all$Right
hh<-ggplot(all, aes(x=orientation, y=leftBias)) + facet_grid(.~dv) + geom_point(color="grey") + stat_summary(fun.y="mean",geom="point",size=4, alpha=.5)
hh<-hh+stat_summary(fun.data="mean_cl_boot",geom="errorbar",width=.3,conf.int=.95,
                  width=5,size=1) 
show(hh)
```

Print effect size
```{r}
leftBiasesCanonical<- filter(all,dv=="efficacy" & orientation=="Canonical")$leftBias
leftBiasCanonical <- mean( leftBiasesCanonical )
leftBiasesInverted<- filter(all,dv=="efficacy" & orientation=="Inverted")$leftBias
leftBiasInverted<- mean(   leftBiasesInverted  )
leftBiasDiff<- leftBiasCanonical - leftBiasInverted
leftBias_sd <- sd(   leftBiasesCanonical - leftBiasesInverted )
```

The leftBiasDiff for this experiment is `r leftBiasDiff` or in Cohen's d `leftBiasDiff / leftBias_sd`, very healthy.


```{r, echo=FALSE}
E1n<- 16
#Raw effect size plus standard error and sd
P1E1canonical=.23;  P1E1c_se = .058; P1E1c_sd = P1E1c_se * sqrt(E1n)
P1E1reversed= .062;  P1E1r_se = .07; P1E1r_sd = P1E1r_se * sqrt(E1n)
#To calculate sd of the bias diff, consider that the variances sum,
#therefore first sum the variances then convert back to standard deviation
#Although only true for *independent* random variables and these unlikely to be totally independent
P1E1diff_sdCalculated = sqrt( (P1E1c_sd^2 + P1E1r_sd^2) )  #.257

E2n<- 24
P1E2canonical=.218; P1E2c_se =.034; P1E2c_sd= P1E2c_se * sqrt(E2n)
P1E2inverted=.017; P1E2i_se =.049; P1E2i_sd = P1E2i_se * sqrt(E2n)
P1E2diff_sdCalculated = sqrt( (P1E2c_sd^2 + P1E2i_sd^2) ) #.2066

P1E2vertUpright=.188; P1E2vu_se=.043; P1E2vu_sd = P1E2vu_se * sqrt(E2n)
P1E2vertInverted= -.07; P1E2vi_se=.049; P1E2vi_sd = P1E2vi_se * sqrt(E2n)
P1E2vdiff_sdCalculated = sqrt( (P1E2vi_sd^2 + P1E2vu_sd^2) )

P1E1leftBiasDiff<- P1E1canonical-P1E1reversed
P1E2leftBiasDiff<- P1E2canonical - P1E2inverted
P1E2vertBiasDiff<- P1E2vertUpright - P1E2vertInverted
#reported as  .258 +/- .047 in the paper

#The diff standard errors are also available from the paper directly. But still need to 
#convert to SD to get Cohen's d.

P1E1diff_se<-.07; P1E1diff_sd<- P1E1diff_se*sqrt(E2n) 
P1E2diff_se<-.038; P1E2diff_sd<- P1E2diff_se*sqrt(E2n) 
P1E2vdiff_se<- .047; P1E2vdiff_sd<- P1E2vdiff_se*sqrt(E2n)

```

What was it for the first paper? For E1,`r P1E1canonical`  Canonical and 
`r P1E1reversed` Mirror-reversed. Difference is `r P1E1canonical-P1E1reversed`
. For E2, bias difference very similar at `r P1E2leftBiasDiff`.
For E2 vertical arrangement, `r P1E2vertBiasDiff`


Do conventional stats.
```{r}

require(ez)

aa <- ezANOVA(data=filter(all,dv=="efficacy"), dv=leftBias, within=orientation, wid=subject)
cat("F=", aa$ANOVA$F, " p=", aa$ANOVA$p, "\n", sep="")

```

Do Bayesian t-test. That is, take the likelihood of the left bias difference observed under the prior and divide it by the likelihood of the left bias difference observed under the null.

Use the default Bayes test (but for E2 will use a custom prior)

```{r, echo=FALSE}
if(!require(BayesFactor)){install.packages('BayesFactor')}
library(BayesFactor)

leftBiasDifferences<- leftBiasesCanonical - leftBiasesInverted

ttestResults<- ttestBF( leftBiasDifferences )

```


The Bayes factor from a one-sample default Bayes t-test for the leftBiasDifferences is `r ttestResults@bayesFactor$bf`

The full results are 
```r 
print(ttestResults)
```

A custom prior would provide more power, as detailed in bayesianAnalysisForPrereg.Rmd in E2 folder

Do the correlogram and correlation
